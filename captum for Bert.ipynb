{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from nlp_cmp_utils import create_data_loader\n",
    "from nlp_cmp_utils import IMDBClassifier\n",
    "from nlp_cmp_utils import explain_tweet_bert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_path = Path('/dataStore/transformers_projects/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'result_2020_11_15.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_id</th>\n",
       "      <th>label_text</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>{stunned}</td>\n",
       "      <td>13</td>\n",
       "      <td>RT @Jwhitbrook: With the new Picard up on Amazon I can finally get a clean screenshot and ask......</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{love}</td>\n",
       "      <td>5</td>\n",
       "      <td>RT @klaushismydaddy: netflix: i love ALL of my programs equally!!! stranger things, lucifer, tig...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{excellent}</td>\n",
       "      <td>5</td>\n",
       "      <td>Just finished Picard on Amazon Prime. Was not expecting to cry. What an excellent show.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{you,suggest,go,do,so.}</td>\n",
       "      <td>5</td>\n",
       "      <td>If you haven’t seen the amazon prime show “Upload”, I suggest you go do so. I really enjoyed thi...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>{\"https://t.co/l2HIKNQ95V\\n\\nWorks\"}</td>\n",
       "      <td>13</td>\n",
       "      <td>@brexitblog_info @boblister_poole https://t.co/l2HIKNQ95V\\n\\nWorks both ways</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>400</td>\n",
       "      <td>1549</td>\n",
       "      <td>{NEVER}</td>\n",
       "      <td>265</td>\n",
       "      <td>RT @Floydbirman: @LoyalDefender2K I have NEVER watch ANY award for decades. Same as BBC Question...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>328</td>\n",
       "      <td>1556</td>\n",
       "      <td>{out,of,touch}</td>\n",
       "      <td>167</td>\n",
       "      <td>RT @annesayer6: @LozzaFox @EquityUK I would suggest actors denounce Equity UK for being complete...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>410</td>\n",
       "      <td>1557</td>\n",
       "      <td>{disgracefully}</td>\n",
       "      <td>265</td>\n",
       "      <td>@JohnSimpsonNews Not to mention anti SNP bias! It’s blatant in Scotland! There is no doubt the b...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>422</td>\n",
       "      <td>1565</td>\n",
       "      <td>{hate}</td>\n",
       "      <td>348</td>\n",
       "      <td>RT @Ally__Cinnamon: Boris Johnson could say I fuckin hate the blacks man and there would be a de...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>403</td>\n",
       "      <td>1587</td>\n",
       "      <td>{anti-government,rhetoric,Nothing,remotely,supportive}</td>\n",
       "      <td>265</td>\n",
       "      <td>@bbcquestiontime BBC Question Time - Mouthpiece of the Labour Party.\\nMiriad of anti-government ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  feature_id                                              label_text  \\\n",
       "0     27           1                                               {stunned}   \n",
       "1      1           2                                                  {love}   \n",
       "2      2           3                                             {excellent}   \n",
       "3      3           5                                 {you,suggest,go,do,so.}   \n",
       "4     25           6                    {\"https://t.co/l2HIKNQ95V\\n\\nWorks\"}   \n",
       "..   ...         ...                                                     ...   \n",
       "423  400        1549                                                 {NEVER}   \n",
       "424  328        1556                                          {out,of,touch}   \n",
       "425  410        1557                                         {disgracefully}   \n",
       "426  422        1565                                                  {hate}   \n",
       "427  403        1587  {anti-government,rhetoric,Nothing,remotely,supportive}   \n",
       "\n",
       "     entry_id  \\\n",
       "0          13   \n",
       "1           5   \n",
       "2           5   \n",
       "3           5   \n",
       "4          13   \n",
       "..        ...   \n",
       "423       265   \n",
       "424       167   \n",
       "425       265   \n",
       "426       348   \n",
       "427       265   \n",
       "\n",
       "                                                                                            feature_text  \\\n",
       "0    RT @Jwhitbrook: With the new Picard up on Amazon I can finally get a clean screenshot and ask......   \n",
       "1    RT @klaushismydaddy: netflix: i love ALL of my programs equally!!! stranger things, lucifer, tig...   \n",
       "2                Just finished Picard on Amazon Prime. Was not expecting to cry. What an excellent show.   \n",
       "3    If you haven’t seen the amazon prime show “Upload”, I suggest you go do so. I really enjoyed thi...   \n",
       "4                           @brexitblog_info @boblister_poole https://t.co/l2HIKNQ95V\\n\\nWorks both ways   \n",
       "..                                                                                                   ...   \n",
       "423  RT @Floydbirman: @LoyalDefender2K I have NEVER watch ANY award for decades. Same as BBC Question...   \n",
       "424  RT @annesayer6: @LozzaFox @EquityUK I would suggest actors denounce Equity UK for being complete...   \n",
       "425  @JohnSimpsonNews Not to mention anti SNP bias! It’s blatant in Scotland! There is no doubt the b...   \n",
       "426  RT @Ally__Cinnamon: Boris Johnson could say I fuckin hate the blacks man and there would be a de...   \n",
       "427  @bbcquestiontime BBC Question Time - Mouthpiece of the Labour Party.\\nMiriad of anti-government ...   \n",
       "\n",
       "    type  \n",
       "0    pos  \n",
       "1    pos  \n",
       "2    pos  \n",
       "3    pos  \n",
       "4    pos  \n",
       "..   ...  \n",
       "423  neg  \n",
       "424  neg  \n",
       "425  neg  \n",
       "426  neg  \n",
       "427  neg  \n",
       "\n",
       "[428 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.type.apply(lambda x: 1 if x=='pos' else 0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE=1\n",
    "\n",
    "# full data set\n",
    "results_batch = create_data_loader(df.feature_text.to_list(), df.label.to_list(), df.label_text.to_list() ,tokenizer , 512, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IMDBClassifier(2, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(data_output_path / 'distilbert_IMDB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.zero_grad()\n",
    "model.cpu()\n",
    "embeddings = model.model.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare with captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml(input_ids, additional_forward_args):\n",
    "    \n",
    "    return torch.softmax(model(input_ids,additional_forward_args),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(ml, embeddings,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 428/428 [1:14:57<00:00, 10.51s/it]\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for batch in tqdm(results_batch):\n",
    "    \n",
    "    attribs = explain_tweet_bert(batch,lig,n_steps=25)\n",
    "    word_parts = tokenizer.batch_decode(batch['input_ids'][0])\n",
    "    \n",
    "    attr_data_df = pd.DataFrame(data=(zip(attribs, word_parts)), columns=('score', 'word')).rename_axis('position')\n",
    "    \n",
    "    # remove ['PAD'] tags - bert only\n",
    "    attr_data_df.reset_index(inplace=True)\n",
    "    word_dict = attr_data_df.loc[attr_data_df.word != '[PAD]'].to_dict(orient='records')\n",
    "    \n",
    "    results.append({'model_dict':word_dict,'human_words':batch['found_label'],'sentiment':batch['label']})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_cap = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tuple_list(inp):\n",
    "    \"\"\"pytorch dataloader turns lists into lists of tuples. this is to correct back\"\"\"\n",
    "    \n",
    "    return [i[0] for i in inp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_cap['human_words']=res_df_cap.human_words.apply(fix_tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_dict</th>\n",
       "      <th>human_words</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'position': 0, 'score': 0.15727868574772647, 'word': '[CLS]'}, {'position': 1, 'score': 0.1249...</td>\n",
       "      <td>[stunned]</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'position': 0, 'score': 0.21714102995484544, 'word': '[CLS]'}, {'position': 1, 'score': 0.0128...</td>\n",
       "      <td>[love]</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'position': 0, 'score': 0.1665978808950008, 'word': '[CLS]'}, {'position': 1, 'score': -0.0337...</td>\n",
       "      <td>[excellent]</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'position': 0, 'score': 0.43073863908028953, 'word': '[CLS]'}, {'position': 1, 'score': 0.0644...</td>\n",
       "      <td>[you, suggest, go, do, so.]</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'position': 0, 'score': 0.1545824975521331, 'word': '[CLS]'}, {'position': 1, 'score': 0.03480...</td>\n",
       "      <td>[\"https://t.co/l2HIKNQ95V\\n\\nWorks\"]</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            model_dict  \\\n",
       "0  [{'position': 0, 'score': 0.15727868574772647, 'word': '[CLS]'}, {'position': 1, 'score': 0.1249...   \n",
       "1  [{'position': 0, 'score': 0.21714102995484544, 'word': '[CLS]'}, {'position': 1, 'score': 0.0128...   \n",
       "2  [{'position': 0, 'score': 0.1665978808950008, 'word': '[CLS]'}, {'position': 1, 'score': -0.0337...   \n",
       "3  [{'position': 0, 'score': 0.43073863908028953, 'word': '[CLS]'}, {'position': 1, 'score': 0.0644...   \n",
       "4  [{'position': 0, 'score': 0.1545824975521331, 'word': '[CLS]'}, {'position': 1, 'score': 0.03480...   \n",
       "\n",
       "                            human_words sentiment  \n",
       "0                             [stunned]       pos  \n",
       "1                                [love]       pos  \n",
       "2                           [excellent]       pos  \n",
       "3           [you, suggest, go, do, so.]       pos  \n",
       "4  [\"https://t.co/l2HIKNQ95V\\n\\nWorks\"]       pos  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_cap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_cap.to_pickle('all_scores_bert_25steps.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
